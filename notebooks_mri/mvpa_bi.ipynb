{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13a3295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/aghavamp/Desktop/Projects')\n",
    "sys.path.append('/Users/aghavamp/Desktop/Projects/bimanual_wrist')\n",
    "sys.path.append('/Users/aghavamp/Desktop/Projects/Functional_Fusion')\n",
    "import getpass\n",
    "import importlib\n",
    "import tqdm\n",
    "\n",
    "import scipy.io as sio\n",
    "import rsatoolbox as rsa\n",
    "from rsatoolbox.io import spm as spm_io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import surfAnalysisPy as surf\n",
    "import SUITPy as suit\n",
    "import nibabel as nb\n",
    "import nitools as nt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import PcmPy as pcm\n",
    "import Functional_Fusion.atlas_map as am\n",
    "import Functional_Fusion.reliability as rel\n",
    "import glob\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "# SET PATHS:\n",
    "baseDir = os.path.join('/Users', getpass.getuser(), 'Desktop', 'Projects', 'bimanual_wrist', 'data', 'fMRI')\n",
    "bidsDir = 'BIDS'\n",
    "anatomicalDir = 'anatomicals'\n",
    "freesurferDir = 'surfaceFreesurfer'\n",
    "surfacewbDir = 'surfaceWB' \n",
    "behavDir = 'behavioural'\n",
    "regDir = 'ROI'\n",
    "atlasDir = '/Volumes/diedrichsen_data$/data/Atlas_templates/fs_LR_32'\n",
    "analysisDir = os.path.join(os.path.dirname(os.path.dirname(baseDir)), 'analysis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d93c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = 1\n",
    "region_labels = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "region_names = ['S1', 'M1', 'PMd', 'PMv', 'SMA', 'V1', 'SPLa', 'SPLp']\n",
    "sn_list = [101,102,103,104,106,107,108,109,110,111,112,113,114,115]\n",
    "hem = ['L','R']\n",
    "atlas,_ = am.get_atlas('fs32k')\n",
    "\n",
    "# Intrinsic ordering of the conditions:\n",
    "rdm_cols = ['bi:0_0', 'bi:0_60', 'bi:0_120', 'bi:0_180', 'bi:0_240', 'bi:0_300',\n",
    "            'bi:60_0', 'bi:60_60', 'bi:60_120', 'bi:60_180', 'bi:60_240', 'bi:60_300',\n",
    "            'bi:120_0', 'bi:120_60', 'bi:120_120', 'bi:120_180', 'bi:120_240', 'bi:120_300',\n",
    "            'bi:180_0', 'bi:180_60', 'bi:180_120', 'bi:180_180', 'bi:180_240', 'bi:180_300',\n",
    "            'bi:240_0', 'bi:240_60', 'bi:240_120', 'bi:240_180', 'bi:240_240', 'bi:240_300',\n",
    "            'bi:300_0', 'bi:300_60', 'bi:300_120', 'bi:300_180', 'bi:300_240', 'bi:300_300', \n",
    "            ]\n",
    "\n",
    "G_matrices = {}\n",
    "D_matrices = {}\n",
    "for sn in sn_list:\n",
    "    regressor_info = pd.read_table(os.path.join(baseDir, f'glm{glm}', f's{sn}', 'reginfo.tsv'))\n",
    "    partitions = regressor_info['run'].values.flatten()\n",
    "    conds = regressor_info['name'].values.flatten()\n",
    "    conds = np.array([cond.strip() for cond in np.array(conds)])\n",
    "    \n",
    "    for j, h in enumerate(hem):\n",
    "        # ==========================================\n",
    "        # DATA EXTRACTION\n",
    "        # ==========================================\n",
    "        #  Define atlas map\n",
    "        white = os.path.join(baseDir, surfacewbDir, f's{sn}', f's{sn}.{h}.white.32k.surf.gii') # Individual white surface\n",
    "        pial = os.path.join(baseDir, surfacewbDir, f's{sn}', f's{sn}.{h}.pial.32k.surf.gii') # Invividual pial surface\n",
    "        mask = os.path.join(baseDir, f'glm{glm}', f's{sn}', 'mask.nii') # Mask in functional space for that subject\n",
    "\n",
    "        # File names for data extraction\n",
    "        nii_names = sorted(glob.glob(os.path.join(baseDir, f'glm{glm}', f's{sn}', \"beta_*.nii\")))\n",
    "        nii_names = nii_names[0:480] # remove the run constant regressors\n",
    "        resMS_name = [os.path.join(baseDir, f'glm{glm}', f's{sn}', 'ResMS.nii')]\n",
    "        \n",
    "        beta = []\n",
    "        resMS = []\n",
    "        beta_white = []\n",
    "        for i, r in enumerate(region_labels):\n",
    "            atlas_tmp = atlas.get_hemisphere(j)\n",
    "            subatlas = atlas_tmp.get_subatlas_image(os.path.join(atlasDir,f'ROI.32k.{h}.label.gii'), value=r)\n",
    "            amap = am.AtlasMapSurf(subatlas.vertex[0],white,pial,mask) # Atlas map\n",
    "            # Compute the voxels in native space\n",
    "            amap.build()\n",
    "            \n",
    "            # This extract all the relevant voxels in native space (use for RSA)\n",
    "            beta = amap.extract_data_native(nii_names)\n",
    "            idx_nan = np.isnan(beta).any(axis=0)\n",
    "            beta = beta[:, ~idx_nan]\n",
    "            resMS = amap.extract_data_native(resMS_name)\n",
    "            resMS = resMS[:, ~idx_nan]\n",
    "            beta_white = beta/np.sqrt(resMS)\n",
    "            \n",
    "            # ========================================== \n",
    "            # Estimated variance-covariance matrix\n",
    "            # ==========================================\n",
    "            # select unimanual conditions:\n",
    "            idx = [tmp in rdm_cols for tmp in conds]\n",
    "            Y = beta_white[idx,:]\n",
    "            cond_vec = conds[idx]\n",
    "            partition_vec = partitions[idx]\n",
    "            Z = utils.please.indicator(cond_vec, rdm_cols)\n",
    "            G_hat,_ = pcm.est_G_crossval(Y,\n",
    "                                         Z,\n",
    "                                         partition_vec,\n",
    "                                         X=pcm.matrix.indicator(partition_vec))\n",
    "            D = np.sign(pcm.G_to_dist(G_hat)) * np.sqrt(np.abs(pcm.G_to_dist(G_hat)))\n",
    "            \n",
    "            key = (sn, h, region_names[i])\n",
    "            G_matrices[key] = G_hat\n",
    "            D_matrices[key] = D\n",
    "\n",
    "# Construct the long DataFrame\n",
    "rows = []\n",
    "for key in G_matrices:\n",
    "    sn, hem, region = key\n",
    "    G = G_matrices[key]\n",
    "    D = D_matrices[key]\n",
    "\n",
    "    row = {'sn': sn, 'hem': hem, 'region': region}\n",
    "    row.update(utils.please.flatten_matrix(G, rdm_cols, 'G'))\n",
    "    row.update(utils.please.flatten_matrix(D, rdm_cols, 'D'))\n",
    "    rows.append(row)\n",
    "\n",
    "ana = pd.DataFrame(rows)\n",
    "ana.to_csv(os.path.join(analysisDir,'G_bi.csv'), index=False)\n",
    "ana.to_feather(os.path.join(analysisDir,'G_bi.feather'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61c8632",
   "metadata": {},
   "source": [
    "## Estimate 36 by 36 mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3bd1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = 1\n",
    "region_labels = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "region_names = ['S1', 'M1', 'PMd', 'PMv', 'SMA', 'V1', 'SPLa', 'SPLp']\n",
    "sn_list = [101,102,103,104,106,107,108,109,110,111,112,113,114,115]\n",
    "hem = ['L','R']\n",
    "atlas,_ = am.get_atlas('fs32k')\n",
    "ana = {'sn':[], \n",
    "       'hem':[],\n",
    "       'region':[],\n",
    "       'cond':[],\n",
    "       'G_hat':[],\n",
    "       'D':[]}\n",
    "\n",
    "for sn in sn_list:\n",
    "    regressor_info = pd.read_table(os.path.join(baseDir, f'glm{glm}', f's{sn}', 'reginfo.tsv'))\n",
    "    partitions = regressor_info['run'].values.flatten()\n",
    "    conds = regressor_info['name'].values.flatten()\n",
    "\n",
    "    for j, h in enumerate(hem):\n",
    "        # ==========================================\n",
    "        # DATA EXTRACTION\n",
    "        # ==========================================\n",
    "        #  Define atlas map\n",
    "        white = os.path.join(baseDir, surfacewbDir, f's{sn}', f's{sn}.{h}.white.32k.surf.gii') # Individual white surface\n",
    "        pial = os.path.join(baseDir, surfacewbDir, f's{sn}', f's{sn}.{h}.pial.32k.surf.gii') # Invividual pial surface\n",
    "        mask = os.path.join(baseDir, f'glm{glm}', f's{sn}', 'mask.nii') # Mask in functional space for that subject\n",
    "\n",
    "        # File names for data extraction\n",
    "        nii_names = sorted(glob.glob(os.path.join(baseDir, f'glm{glm}', f's{sn}', \"beta_*.nii\")))\n",
    "        nii_names = nii_names[0:480] # remove the run constant regressors\n",
    "        resMS_name = [os.path.join(baseDir, f'glm{glm}', f's{sn}', 'ResMS.nii')]\n",
    "\n",
    "        beta = []\n",
    "        resMS = []\n",
    "        beta_white = []\n",
    "        for i, r in enumerate(region_labels):\n",
    "            atlas_tmp = atlas.get_hemisphere(j)\n",
    "            subatlas = atlas_tmp.get_subatlas_image(os.path.join(atlasDir,f'ROI.32k.{h}.label.gii'), value=r)\n",
    "            amap = am.AtlasMapSurf(subatlas.vertex[0],white,pial,mask) # Atlas map\n",
    "            # Compute the voxels in native space\n",
    "            amap.build()\n",
    "\n",
    "            # This extract all the relevant voxels in native space (use for RSA)\n",
    "            beta = amap.extract_data_native(nii_names)\n",
    "            idx_nan = np.isnan(beta).any(axis=0)\n",
    "            beta = beta[:, ~idx_nan]\n",
    "            resMS = amap.extract_data_native(resMS_name)\n",
    "            resMS = resMS[:, ~idx_nan]\n",
    "            beta_white = beta/np.sqrt(resMS)\n",
    "            \n",
    "            # ========================================== \n",
    "            # Estimated variance-covariance matrix\n",
    "            # ==========================================\n",
    "            # select unimanual conditions:\n",
    "            idx = ['bi' in tmp for tmp in conds]\n",
    "            Y = beta_white[idx,:]\n",
    "            cond_vec = conds[idx]\n",
    "            partition_vec = partitions[idx]\n",
    "            G_hat,_ = pcm.est_G_crossval(Y,\n",
    "                                         cond_vec,\n",
    "                                         partition_vec,\n",
    "                                         X=pcm.matrix.indicator(partition_vec))\n",
    "            D = np.sign(pcm.G_to_dist(G_hat)) * np.sqrt(np.abs(pcm.G_to_dist(G_hat)))\n",
    "            \n",
    "            ana['sn'].append(sn)\n",
    "            ana['hem'].append(h)\n",
    "            ana['region'].append(region_names[i])\n",
    "            ana['cond'].append(cond_vec)\n",
    "\n",
    "            # G_hat, indices = utils.please.matrix_to_vector(G_hat, include_diagonal=True)\n",
    "            # D,_ = utils.please.matrix_to_vector(D, include_diagonal=True)\n",
    "            # ana['row'] = indices[0]\n",
    "            # ana['col'] = indices[1]\n",
    "            ana['G_hat'].append(G_hat)\n",
    "            ana['D'].append(D)\n",
    "\n",
    "ana = pd.DataFrame(ana)\n",
    "# ana.to_csv(os.path.join(analysisDir,'G_uni.csv'), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adcee1b",
   "metadata": {},
   "source": [
    "## PLOT G 36 by 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_list = ana.sn.unique()\n",
    "hem = ana.hem.unique()\n",
    "regions = ana.region.unique()\n",
    "\n",
    "conds = ana.cond[0][0:36]\n",
    "custom_order = np.array(['bi:0_0    ', 'bi:0_60   ', 'bi:0_120  ', 'bi:0_180  ', 'bi:0_240  ', 'bi:0_300  ',\n",
    "                         'bi:60_0   ', 'bi:60_60  ', 'bi:60_120 ', 'bi:60_180 ', 'bi:60_240 ', 'bi:60_300 ',\n",
    "                         'bi:120_0  ', 'bi:120_60 ', 'bi:120_120', 'bi:120_180', 'bi:120_240', 'bi:120_300',\n",
    "                         'bi:180_0  ', 'bi:180_60 ', 'bi:180_120', 'bi:180_180', 'bi:180_240', 'bi:180_300',\n",
    "                         'bi:240_0  ', 'bi:240_60 ', 'bi:240_120', 'bi:240_180', 'bi:240_240', 'bi:240_300',\n",
    "                         'bi:300_0  ', 'bi:300_60 ', 'bi:300_120', 'bi:300_180', 'bi:300_240', 'bi:300_300', \n",
    "                         ])\n",
    "\n",
    "# Create a mapping of the current order to their indices\n",
    "order_map = {cond: idx for idx, cond in enumerate(conds)}\n",
    "# Get the indices for the custom order\n",
    "sort_indices = [order_map[cond] for cond in custom_order]\n",
    "\n",
    "G_avg = np.zeros((len(hem),len(regions), len(conds), len(conds)))\n",
    "n_cond = len(conds)\n",
    "for sn in sn_list:\n",
    "    for j, h in enumerate(hem):\n",
    "        for i,_ in enumerate(regions):\n",
    "            fig, ax = plt.subplots(figsize=(7,7))\n",
    "            # Apply sorting to the data\n",
    "            G_hat = ana[(ana.sn==sn) & (ana.hem==h) & (ana.region==regions[i])].G_hat.values[0]\n",
    "            G_hat = G_hat[np.ix_(sort_indices, sort_indices)]\n",
    "            v_max = np.max(G_hat)\n",
    "            v_min = np.min(G_hat)\n",
    "            v_max = max(abs(v_max), abs(v_min))\n",
    "            sns.heatmap(G_hat, cmap='viridis', square=True, cbar_kws={'label': ''}, ax=ax, vmin=-v_max, vmax=v_max)\n",
    "            ax.set_title(f'G, {region_names[i]}_{h}, s{sn}', fontsize=10)\n",
    "            \n",
    "            # Overlay squares\n",
    "            # for x, y, w, h in squares:\n",
    "            #     rect = patches.Rectangle((x, y), w, h, linewidth=1.5, edgecolor='black', facecolor='none')\n",
    "            #     ax.add_patch(rect)\n",
    "\n",
    "            # Set labels manually with more formatting options\n",
    "            ax.set_xticks(np.arange(0,n_cond)+0.5)\n",
    "            ax.set_xticklabels(custom_order, rotation=90, fontsize=8, fontweight='bold')\n",
    "            ax.set_yticks(np.arange(0,n_cond)+0.5)\n",
    "            ax.set_yticklabels(custom_order, rotation=0, fontsize=8, fontweight='bold')\n",
    "\n",
    "            G_avg[j,i,:,:] = G_avg[j,i,:,:] + G_hat/len(sn_list)\n",
    "        \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../figures/G_bi/G_{region_names[i]}{h}_s{sn}.pdf', bbox_inches=\"tight\")\n",
    "            plt.close(fig)\n",
    "\n",
    "# AVG G PLOT:\n",
    "for j, h in enumerate(hem):\n",
    "    for i, ax in enumerate(regions):\n",
    "        fig, ax = plt.subplots(figsize=(7,7))\n",
    "        \n",
    "        # Apply sorting to the data\n",
    "        G_hat = G_avg[j,i,:,:]\n",
    "        v_max = np.max(G_hat)\n",
    "        v_min = np.min(G_hat)\n",
    "        v_max = max(abs(v_max), abs(v_min))\n",
    "        sns.heatmap(G_hat, cmap='viridis', square=True, cbar_kws={'label': ''}, ax=ax, vmin=-v_max, vmax=v_max)\n",
    "        ax.set_title(f'AVG G, {region_names[i]}_{h}', fontsize=10)\n",
    "        # Set labels manually with more formatting options\n",
    "        ax.set_xticks(np.arange(0,n_cond)+0.5)\n",
    "        ax.set_xticklabels(custom_order, rotation=90, fontsize=6, fontweight='bold')\n",
    "        ax.set_yticks(np.arange(0,n_cond)+0.5)\n",
    "        ax.set_yticklabels(custom_order, rotation=0, fontsize=6, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'../figures/G_bi/G_avg_{region_names[i]}{h}.pdf', bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b0fb99",
   "metadata": {},
   "source": [
    "## PLOT D 36 by 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2859fec8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ana' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m sn_list = \u001b[43mana\u001b[49m.sn.unique()\n\u001b[32m      2\u001b[39m hem = ana.hem.unique()\n\u001b[32m      3\u001b[39m regions = ana.region.unique()\n",
      "\u001b[31mNameError\u001b[39m: name 'ana' is not defined"
     ]
    }
   ],
   "source": [
    "sn_list = ana.sn.unique()\n",
    "hem = ana.hem.unique()\n",
    "regions = ana.region.unique()\n",
    "\n",
    "conds = ana.cond[0][0:36]\n",
    "custom_order = np.array(['bi:0_0    ', 'bi:0_60   ', 'bi:0_120  ', 'bi:0_180  ', 'bi:0_240  ', 'bi:0_300  ',\n",
    "                         'bi:60_0   ', 'bi:60_60  ', 'bi:60_120 ', 'bi:60_180 ', 'bi:60_240 ', 'bi:60_300 ',\n",
    "                         'bi:120_0  ', 'bi:120_60 ', 'bi:120_120', 'bi:120_180', 'bi:120_240', 'bi:120_300',\n",
    "                         'bi:180_0  ', 'bi:180_60 ', 'bi:180_120', 'bi:180_180', 'bi:180_240', 'bi:180_300',\n",
    "                         'bi:240_0  ', 'bi:240_60 ', 'bi:240_120', 'bi:240_180', 'bi:240_240', 'bi:240_300',\n",
    "                         'bi:300_0  ', 'bi:300_60 ', 'bi:300_120', 'bi:300_180', 'bi:300_240', 'bi:300_300', \n",
    "                         ])\n",
    "\n",
    "# Create a mapping of the current order to their indices\n",
    "order_map = {cond: idx for idx, cond in enumerate(conds)}\n",
    "# Get the indices for the custom order\n",
    "sort_indices = [order_map[cond] for cond in custom_order]\n",
    "\n",
    "D_avg = np.zeros((len(hem),len(regions), len(conds), len(conds)))\n",
    "n_cond = len(conds)\n",
    "for sn in sn_list:\n",
    "    for j, h in enumerate(hem):\n",
    "        for i,_ in enumerate(regions):\n",
    "            fig, ax = plt.subplots(figsize=(7,7))\n",
    "            # Apply sorting to the data\n",
    "            D = ana[(ana.sn==sn) & (ana.hem==h) & (ana.region==regions[i])].D.values[0]\n",
    "            D = D[np.ix_(sort_indices, sort_indices)]\n",
    "            v_max = np.max(D)\n",
    "            v_min = np.min(D)\n",
    "            v_max = max(abs(v_max), abs(v_min))\n",
    "            sns.heatmap(D, cmap='viridis', square=True, cbar_kws={'label': ''}, ax=ax, vmin=-v_max, vmax=v_max)\n",
    "            ax.set_title(f'D, {region_names[i]}_{h}, s{sn}', fontsize=10)\n",
    "\n",
    "            # Set labels manually with more formatting options\n",
    "            ax.set_xticks(np.arange(0,n_cond)+0.5)\n",
    "            ax.set_xticklabels(custom_order, rotation=90, fontsize=6, fontweight='bold')\n",
    "            ax.set_yticks(np.arange(0,n_cond)+0.5)\n",
    "            ax.set_yticklabels(custom_order, rotation=0, fontsize=6, fontweight='bold')\n",
    "\n",
    "            D_avg[j,i,:,:] = D_avg[j,i,:,:] + D/len(sn_list)\n",
    "        \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'../figures/D_bi/D_{region_names[i]}{h}_s{sn}.pdf', bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "\n",
    "# AVG D PLOT:\n",
    "for j, h in enumerate(hem):\n",
    "    for i, _ in enumerate(regions):\n",
    "        fig, ax = plt.subplots(figsize=(7,7))\n",
    "        # Apply sorting to the data\n",
    "        D = D_avg[j,i,:,:]\n",
    "        v_max = np.max(D)\n",
    "        v_min = np.min(D)\n",
    "        v_max = max(abs(v_max), abs(v_min))\n",
    "        sns.heatmap(D, cmap='viridis', square=True, cbar_kws={'label': ''}, ax=ax, vmin=-v_max, vmax=v_max)\n",
    "        ax.set_title(f'AVG D, {region_names[i]}_{h}', fontsize=10)\n",
    "        # Set labels manually with more formatting options\n",
    "        ax.set_xticks(np.arange(0,n_cond)+0.5)\n",
    "        ax.set_xticklabels(custom_order, rotation=90, fontsize=8, fontweight='bold')\n",
    "        ax.set_yticks(np.arange(0,n_cond)+0.5)\n",
    "        ax.set_yticklabels(custom_order, rotation=0, fontsize=8, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'../figures/D_bi/D_avg_{region_names[i]}{h}.pdf', bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
