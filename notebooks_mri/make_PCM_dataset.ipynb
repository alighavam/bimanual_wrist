{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34138728",
   "metadata": {},
   "source": [
    "Make pcm datasets for subsequent analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d011d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "import sys\n",
    "import getpass\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# user path:\n",
    "usrname = getpass.getuser()\n",
    "# add paths:\n",
    "sys.path.append(f'/Users/{usrname}/Desktop/Projects')\n",
    "sys.path.append(f'/Users/{usrname}/Desktop/Projects/bimanual_wrist')\n",
    "sys.path.append(f'/Users/{usrname}/Desktop/Projects/Functional_Fusion')\n",
    "sys.path.append(f'/Users/{usrname}/Desktop/Projects/PcmPy')\n",
    "\n",
    "\n",
    "import rsatoolbox as rsa\n",
    "from rsatoolbox.io import spm as spm_io\n",
    "import surfAnalysisPy as surf\n",
    "import SUITPy as suit\n",
    "import nibabel as nb\n",
    "import nitools as nt\n",
    "import PcmPy as pcm\n",
    "import Functional_Fusion.atlas_map as am\n",
    "import Functional_Fusion.reliability as rel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "# SET PATHS:\n",
    "baseDir = os.path.join('/Users', getpass.getuser(), 'Desktop', 'Projects', 'bimanual_wrist', 'data', 'fMRI')\n",
    "bidsDir = 'BIDS'\n",
    "anatomicalDir = 'anatomicals'\n",
    "freesurferDir = 'surfaceFreesurfer'\n",
    "surfacewbDir = 'surfaceWB' \n",
    "behavDir = 'behavioural'\n",
    "regDir = 'ROI'\n",
    "atlasDir = '/Volumes/diedrichsen_data$/data/Atlas_templates/fs_LR_32'\n",
    "analysisDir = os.path.join(os.path.dirname(os.path.dirname(baseDir)), 'analysis')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3fa139",
   "metadata": {},
   "source": [
    "# Unimanual 12by12 Intrinsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d464dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['flx', 'flxup', 'extup', 'ext', 'extdn', 'flxdn', 'flx', 'flxup', 'extup', 'ext', 'extdn', 'flxdn']\n",
    "labels_lateral = ['contra']*6 + ['ipsi']*6\n",
    "cmap = 'RdBu_r'\n",
    "sn_bad = [102, 103]\n",
    "regions = ['M1','S1','PMd','PMv','SMA','SPLa','SPLp','V1']\n",
    "hem = ['L','R']\n",
    "\n",
    "for region in regions:\n",
    "    data, cond_vec, part_vec = [], [], []\n",
    "    for i_hem, h in enumerate(hem):\n",
    "        roi = f'{region}_{h}'\n",
    "        file_path = os.path.join(analysisDir, f'pwbeta_{roi}.npz')\n",
    "        d = np.load(file_path, allow_pickle=True)\n",
    "\n",
    "        subject = d['subject']\n",
    "        indices = [k for k, s in enumerate(subject) if s not in sn_bad]\n",
    "\n",
    "        subject = d['subject'][indices]\n",
    "        cond_name_tmp = d['cond_intrinsic_vec'][indices]\n",
    "        cond_vec_tmp = d['cond_num_vec'][indices]\n",
    "        data_tmp = d['beta_white'][indices]\n",
    "        part_tmp = d['part_vec'][indices]\n",
    "\n",
    "        for i_sub in range(len(subject)):\n",
    "            idx1 = [j for j, c in enumerate(cond_name_tmp[i_sub]) if 'rhand' in c]\n",
    "            idx2 = [j for j, c in enumerate(cond_name_tmp[i_sub]) if 'lhand' in c]\n",
    "            idx = idx1 + idx2\n",
    "            # Y = data_tmp[i_sub][idx, :]\n",
    "            Y1 = data_tmp[i_sub][idx1, :]\n",
    "            Y2 = data_tmp[i_sub][idx2, :]\n",
    "\n",
    "            # remove mean of voxels across conditions of rhand:\n",
    "            # rhand_parts = part_tmp[i_sub][idx1]\n",
    "            # for p in np.unique(rhand_parts):\n",
    "            #     Y1[rhand_parts == p, :] = Y1[rhand_parts == p, :] - np.mean(Y1[rhand_parts == p, :], axis=0)\n",
    "            # # remove mean of voxels across conditions of lhand:\n",
    "            # lhand_parts = part_tmp[i_sub][idx2]\n",
    "            # for p in np.unique(lhand_parts):\n",
    "            #     Y2[lhand_parts == p, :] = Y2[lhand_parts == p, :] - np.mean(Y2[lhand_parts == p, :], axis=0)\n",
    "\n",
    "            # we need to sort contralateral first:\n",
    "            Y = data_tmp[i_sub][idx, :]\n",
    "\n",
    "            # make partition vec:\n",
    "            subj_part = part_tmp[i_sub][idx]\n",
    "            \n",
    "            # make condition vec:\n",
    "            subj_cond_rhand = cond_vec_tmp[i_sub][idx1]\n",
    "            subj_cond_lhand = cond_vec_tmp[i_sub][idx2]\n",
    "            if h == 'L':\n",
    "                # we want rhand to come first in terms of condition numbering\n",
    "                # because it's contralateral for left hem:\n",
    "                subj_cond_rhand = subj_cond_rhand - 6\n",
    "                subj_cond_lhand = subj_cond_lhand + 6\n",
    "            \n",
    "            subj_cond = np.concatenate((subj_cond_rhand, subj_cond_lhand), axis=0)\n",
    "\n",
    "            data.append(Y)\n",
    "            cond_vec.append(np.array(subj_cond))\n",
    "            part_vec.append(subj_part)\n",
    "\n",
    "    Y = []\n",
    "    # --- dataset ---\n",
    "    for i_sub in range(len(data)):\n",
    "        obs_des = {'cond_vec': cond_vec[i_sub], 'part_vec': part_vec[i_sub]}\n",
    "        Y.append(pcm.dataset.Dataset(data[i_sub], obs_descriptors=obs_des))\n",
    "\n",
    "    # save PCM dataset (Y):\n",
    "    file_path_save = os.path.join(analysisDir, f'pcm_dataset_12by12_{region}.npz')\n",
    "    np.savez(file_path_save, Y=Y, cond_vec=cond_vec, part_vec=part_vec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64b720a",
   "metadata": {},
   "source": [
    "# Unimanual 12by12 Extrinsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d879594",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['flx', 'flxup', 'extup', 'ext', 'extdn', 'flxdn', 'flx', 'flxup', 'extup', 'ext', 'extdn', 'flxdn']\n",
    "labels_extrinsic = ['0','60','120','180','240','300']*2\n",
    "labels_lateral = ['contra']*6 + ['ipsi']*6\n",
    "cmap = 'RdBu_r'\n",
    "sn_bad = [102, 103]\n",
    "regions = ['M1','S1','PMd','PMv','SMA','SPLa','SPLp','V1']\n",
    "hem = ['L','R']\n",
    "for region in regions:\n",
    "    data, cond_vec, part_vec = [], [], []\n",
    "    for i_hem, h in enumerate(hem):\n",
    "        roi = f'{region}_{h}'\n",
    "        file_path = os.path.join(analysisDir, f'pwbeta_{roi}.npz')\n",
    "        d = np.load(file_path, allow_pickle=True)\n",
    "\n",
    "        subject = d['subject']\n",
    "        indices = [k for k, s in enumerate(subject) if s not in sn_bad]\n",
    "\n",
    "        subject = d['subject'][indices]\n",
    "        cond_name_tmp = d['cond_extrinsic_vec'][indices]\n",
    "        cond_vec_tmp = d['cond_num_vec_extrinsic'][indices]\n",
    "        data_tmp = d['beta_white'][indices]\n",
    "        part_tmp = d['part_vec'][indices]\n",
    "\n",
    "        for i_sub in range(len(subject)):\n",
    "            idx1 = [j for j, c in enumerate(cond_name_tmp[i_sub]) if 'rhand' in c]\n",
    "            idx2 = [j for j, c in enumerate(cond_name_tmp[i_sub]) if 'lhand' in c]\n",
    "            idx = idx1 + idx2\n",
    "            # Y = data_tmp[i_sub][idx, :]\n",
    "            Y1 = data_tmp[i_sub][idx1, :]\n",
    "            Y2 = data_tmp[i_sub][idx2, :]\n",
    "\n",
    "            # remove mean of voxels across conditions of rhand:\n",
    "            # rhand_parts = part_tmp[i_sub][idx1]\n",
    "            # for p in np.unique(rhand_parts):\n",
    "            #     Y1[rhand_parts == p, :] = Y1[rhand_parts == p, :] - np.mean(Y1[rhand_parts == p, :], axis=0)\n",
    "            # # remove mean of voxels across conditions of lhand:\n",
    "            # lhand_parts = part_tmp[i_sub][idx2]\n",
    "            # for p in np.unique(lhand_parts):\n",
    "            #     Y2[lhand_parts == p, :] = Y2[lhand_parts == p, :] - np.mean(Y2[lhand_parts == p, :], axis=0)\n",
    "            Y = np.vstack((Y1, Y2))\n",
    "            \n",
    "            subj_part = part_tmp[i_sub][idx]\n",
    "            # Sort based on Hemisphere to have contralateral first:\n",
    "            if h == 'L':\n",
    "                subj_cond = cond_vec_tmp[i_sub][idx]\n",
    "                tmp = subj_cond.copy()\n",
    "                subj_cond[tmp > 5] = tmp[tmp > 5] - 6\n",
    "                subj_cond[tmp <= 5] = tmp[tmp <= 5] + 6 \n",
    "            elif h == 'R':\n",
    "                subj_cond = cond_vec_tmp[i_sub][idx]\n",
    "\n",
    "            data.append(Y)\n",
    "            cond_vec.append(np.array(subj_cond))\n",
    "            part_vec.append(subj_part)\n",
    "\n",
    "    Y = []\n",
    "    # --- RDM Calculation ---\n",
    "    for i_sub in range(len(data)):\n",
    "        obs_des = {'cond_vec': cond_vec[i_sub], 'part_vec': part_vec[i_sub]}\n",
    "        Y.append(pcm.dataset.Dataset(data[i_sub], obs_descriptors=obs_des))\n",
    "\n",
    "    N = len(Y)\n",
    "    ncond = len(np.unique(Y[0].obs_descriptors['cond_vec']))\n",
    "    G_hat = np.zeros((N, ncond, ncond))\n",
    "    for i_sub in range(N):\n",
    "        G_hat[i_sub, :, :], _ = pcm.est_G_crossval(Y[i_sub].measurements,\n",
    "                                                    Y[i_sub].obs_descriptors['cond_vec'],\n",
    "                                                    Y[i_sub].obs_descriptors['part_vec'],\n",
    "                                                    X=pcm.matrix.indicator(Y[i_sub].obs_descriptors['part_vec']))\n",
    "\n",
    "    # show all second moment matrices\n",
    "    # cmap = 'RdBu_r'\n",
    "    # fig,ax = plt.subplots(4,7,figsize=(30,12))\n",
    "    # vmax = np.abs(G_hat).max()\n",
    "    # for i in range(N):\n",
    "    #     ax[i//7,i%7].imshow(G_hat[i,:,:],vmin=-vmax,vmax=vmax,cmap=cmap)\n",
    "    #     # color bar:\n",
    "    #     sm = ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=-vmax, vmax=vmax))\n",
    "    #     sm.set_array([])\n",
    "    #     cbar = plt.colorbar(sm, ax=ax[i//7,i%7], fraction=0.046, pad=0.04)\n",
    "    #     cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "    # avg:\n",
    "    # fig, ax = plt.subplots(1,2,figsize=(7,3))\n",
    "    # G_hat_avg = np.mean(G_hat, axis=0)\n",
    "    # # G_hat_avg = G_hat_avg / np.trace(G_hat_avg)\n",
    "    # vmax_avg = np.abs(G_hat_avg).max()\n",
    "    # ax[0].imshow(G_hat_avg, vmin=-vmax_avg, vmax=vmax_avg, cmap=cmap)\n",
    "    # sm = ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=-vmax_avg, vmax=vmax_avg))\n",
    "    # sm.set_array([])\n",
    "    # cbar = plt.colorbar(sm, ax=ax[0], fraction=0.046, pad=0.04)\n",
    "    # cbar.ax.tick_params(labelsize=8)\n",
    "    # ax[0].set_title(f'Average G')\n",
    "    # ax[0].axhline(5.5, color='k', linestyle=':', linewidth=1.5)\n",
    "    # ax[0].axvline(5.5, color='k', linestyle=':', linewidth=1.5)\n",
    "\n",
    "    # D_avg = pcm.G_to_dist(G_hat_avg)\n",
    "    # D_avg = np.sign(D_avg) * np.sqrt(np.abs(D_avg))\n",
    "    # vmax = np.abs(D_avg).max()\n",
    "    # ax[1].imshow(D_avg, vmin=-vmax, vmax=vmax, cmap=cmap)\n",
    "    # sm = ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=-vmax, vmax=vmax))\n",
    "    # sm.set_array([])\n",
    "    # cbar = plt.colorbar(sm, ax=ax[1], fraction=0.046, pad=0.04)\n",
    "    # cbar.ax.tick_params(labelsize=8)\n",
    "    # ax[1].set_title(f'Average D')\n",
    "    # ax[1].axhline(5.5, color='k', linestyle=':', linewidth=1.5)\n",
    "    # ax[1].axvline(5.5, color='k', linestyle=':', linewidth=1.5)\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    # save PCM dataset (Y):\n",
    "    file_path_save = os.path.join(analysisDir, f'pcm_dataset_extrinsic_12by12_{region}.npz')\n",
    "    np.savez(file_path_save, Y=Y, cond_vec=cond_vec, part_vec=part_vec)\n",
    "\n",
    "    # # save mean G:\n",
    "    # file_path_save = os.path.join(analysisDir, f'pcm_Ghat_avg_12by12_{region}.npz')\n",
    "    # np.savez(file_path_save, G_hat=G_hat_avg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b988452",
   "metadata": {},
   "source": [
    "# Unimanual 6by6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "942fa6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['M1','S1','PMd','PMv','SMA','SPLa','SPLp','V1']\n",
    "labels = ['flx', 'flxup', 'extup', 'ext', 'extdn', 'flxdn']\n",
    "cmap = 'RdBu_r' \n",
    "sn_bad = [102, 103]\n",
    "\n",
    "for region in regions:\n",
    "    conditions = ['lhand', 'rhand', 'lhand', 'rhand']\n",
    "    rois = [f'{region}_R',f'{region}_L', f'{region}_L', f'{region}_R']\n",
    "    data, cond_vec, part_vec = [], [], []\n",
    "    for roi, condition in zip(rois, conditions):\n",
    "        file_path = os.path.join(analysisDir, f'pwbeta_{roi}.npz')\n",
    "        d = np.load(file_path, allow_pickle=True)\n",
    "\n",
    "        subject = d['subject']\n",
    "        indices = [k for k, s in enumerate(subject) if s not in sn_bad]\n",
    "        \n",
    "        subject = d['subject'][indices]\n",
    "        cond_name_tmp = d['cond_intrinsic_vec'][indices]\n",
    "        cond_vec_tmp = d['cond_num_vec'][indices]\n",
    "        data_tmp = d['beta_white'][indices]\n",
    "        part_tmp = d['part_vec'][indices]\n",
    "        \n",
    "        for i_sub in range(len(subject)):\n",
    "            if condition == 'lhand' or condition == 'rhand':\n",
    "                # Filter for the current condition\n",
    "                idx = [j for j, c in enumerate(cond_name_tmp[i_sub]) if condition in c]\n",
    "                Y = data_tmp[i_sub][idx, :]\n",
    "                subj_cond = cond_vec_tmp[i_sub][idx]\n",
    "                subj_part = part_tmp[i_sub][idx]\n",
    "\n",
    "            data.append(Y)\n",
    "            cond_vec.append(np.array(subj_cond))\n",
    "            part_vec.append(subj_part)\n",
    "\n",
    "    Y = []\n",
    "    for i_sub in range(len(data)):\n",
    "        obs_des = {'cond_vec': cond_vec[i_sub], 'part_vec': part_vec[i_sub]}\n",
    "        Y.append(pcm.dataset.Dataset(data[i_sub], obs_descriptors=obs_des))\n",
    "\n",
    "    # save PCM dataset (Y):\n",
    "    file_path_save = os.path.join(analysisDir, f'pcm_dataset_6by6_{region}.npz')\n",
    "    np.savez(file_path_save, Y=Y, cond_vec=cond_vec, part_vec=part_vec, label=labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d8697",
   "metadata": {},
   "source": [
    "# Bimanual 36by36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aeeea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'L': ['bi:flx_flx', 'bi:flxup_flx', 'bi:extup_flx', 'bi:ext_flx', 'bi:extdn_flx', 'bi:flxdn_flx', \n",
    "                'bi:flx_flxup', 'bi:flxup_flxup', 'bi:extup_flxup', 'bi:ext_flxup', 'bi:extdn_flxup', 'bi:flxdn_flxup', \n",
    "                'bi:flx_extup', 'bi:flxup_extup', 'bi:extup_extup', 'bi:ext_extup', 'bi:extdn_extup', 'bi:flxdn_extup', \n",
    "                'bi:flx_ext', 'bi:flxup_ext', 'bi:extup_ext', 'bi:ext_ext', 'bi:extdn_ext', 'bi:flxdn_ext', \n",
    "                'bi:flx_extdn', 'bi:flxup_extdn', 'bi:extup_extdn', 'bi:ext_extdn', 'bi:extdn_extdn', 'bi:flxdn_extdn', \n",
    "                'bi:flx_flxdn', 'bi:flxup_flxdn', 'bi:extup_flxdn', 'bi:ext_flxdn', 'bi:extdn_flxdn', 'bi:flxdn_flxdn' ],\n",
    "\n",
    "          'R': ['bi:flx_flx',    'bi:flx_flxup',   'bi:flx_extup',   'bi:flx_ext',   'bi:flx_extdn',   'bi:flx_flxdn',\n",
    "                'bi:flxup_flx',  'bi:flxup_flxup', 'bi:flxup_extup', 'bi:flxup_ext', 'bi:flxup_extdn', 'bi:flxup_flxdn',\n",
    "                'bi:extup_flx',  'bi:extup_flxup', 'bi:extup_extup', 'bi:extup_ext', 'bi:extup_extdnn', 'bi:extup_flxdn',\n",
    "                'bi:ext_flx',    'bi:ext_flxup',   'bi:ext_extup',   'bi:ext_ext',   'bi:ext_extdn',   'bi:ext_flxdn',\n",
    "                'bi:extdn_flx',  'bi:extdn_flxup', 'bi:extdn_extup', 'bi:extdn_ext', 'bi:extdn_extdn', 'bi:extdn_flxdn',\n",
    "                'bi:flxdn_flx',  'bi:flxdn_flxup', 'bi:flxdn_extup', 'bi:flxdn_ext', 'bi:flxdn_extdn', 'bi:flxdn_flxdn']\n",
    "}\n",
    "\n",
    "cmap = 'RdBu_r'\n",
    "sn_bad = [102,103]\n",
    "regions = ['M1','S1','PMd','PMv','SMA','SPLa','SPLp','V1']\n",
    "\n",
    "for i_region, region in enumerate(regions):\n",
    "    Y = []\n",
    "    # enumerate hemispheres so we get an integer index for axes\n",
    "    for hem_idx, hem in enumerate(['L','R']):\n",
    "        roi = f'{region}_{hem}'\n",
    "        data, cond_vec, part_vec = [], [], []\n",
    "        file_path = os.path.join(analysisDir, f'pwbeta_{roi}.npz')\n",
    "        d = np.load(file_path, allow_pickle=True)\n",
    "        \n",
    "        subject = d['subject']\n",
    "        indices = [k for k, s in enumerate(subject) if s not in sn_bad]\n",
    "\n",
    "        subject = d['subject'][indices]\n",
    "        cond_name_tmp = d['cond_intrinsic_vec'][indices]\n",
    "        if hem == 'R':\n",
    "            cond_vec_tmp = d['cond_num_vec'][indices]\n",
    "        else:\n",
    "            cond_vec_tmp = d['cond_num_lhem_bimanual_vec'][indices]\n",
    "        data_tmp = d['beta_white'][indices]\n",
    "        part_tmp = d['part_vec'][indices]\n",
    "\n",
    "        for i_sub in range(len(subject)):\n",
    "            # Filter for the current condition\n",
    "            idx = [j for j, c in enumerate(cond_name_tmp[i_sub]) if 'bi' in c]\n",
    "            Ytmp = data_tmp[i_sub][idx, :]\n",
    "            subj_cond = cond_vec_tmp[i_sub][idx]\n",
    "            subj_part = part_tmp[i_sub][idx]\n",
    "\n",
    "            data.append(Ytmp)\n",
    "            cond_vec.append(np.array(subj_cond))\n",
    "            part_vec.append(subj_part)\n",
    "        \n",
    "        for i_sub in range(len(data)):\n",
    "            obs_des = {'cond_vec': cond_vec[i_sub], 'part_vec': part_vec[i_sub]}\n",
    "            Y.append(pcm.dataset.Dataset(data[i_sub], obs_descriptors=obs_des))\n",
    "    \n",
    "    # save PCM dataset (Y):\n",
    "    file_path_save = os.path.join(analysisDir, f'pcm_dataset_bimanual_{region}.npz')\n",
    "    np.savez(file_path_save, Y=Y, cond_vec=cond_vec, part_vec=part_vec)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
