{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/aghavamp/Desktop/Projects/')\n",
    "\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "import rsatoolbox as rsa\n",
    "from rsatoolbox.io import spm as spm_io\n",
    "import matplotlib.pyplot as plt\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import surfAnalysisPy as surf\n",
    "import nibabel as nb\n",
    "import nitools as nt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import PcmPy as pcm\n",
    "import glob\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "# SET PATHS:\n",
    "# baseDir = '/Users/alighavam/Desktop/Projects/bimanual_wrist/data/fMRI'\n",
    "baseDir = os.path.join('/Users', getpass.getuser(), 'Desktop', 'Projects', 'bimanual_wrist', 'data', 'fMRI')\n",
    "bidsDir = 'BIDS'\n",
    "anatomicalDir = 'anatomicals'\n",
    "freesurferDir = 'surfaceFreesurfer'\n",
    "surfacewbDir = 'surfaceWB' \n",
    "behavDir = 'behavioural'\n",
    "regDir = 'ROI'\n",
    "atlasDir = '/Volumes/diedrichsen_data$/data/Atlas_templates/fs_LR_32'\n",
    "analysisDir = os.path.join(os.path.dirname(os.path.dirname(baseDir)), 'analysis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series per run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_names = ['_l', 'S1_l', 'M1_l', 'PMd_l', 'PMv_l', 'SMA_l', 'V1_l', 'SPLa_l', 'SPLp_l', \n",
    "             '_r', 'S1_r', 'M1_r', 'PMd_r', 'PMv_r', 'SMA_r', 'V1_r', 'SPLa_r', 'SPLp_r'] # 18 values\n",
    "glm = 5\n",
    "pre_idx = 8\n",
    "post_idx = 21\n",
    "participants = [101,102,103,104,106,107,108]\n",
    "\n",
    "region = 1\n",
    "\n",
    "def extract_snippets(y, pre, post, onsets):\n",
    "    snippets_y = []\n",
    "    \n",
    "    for onset in onsets:\n",
    "        onset_frame = np.round(onset).astype(int) # the fMRI volume closest to the onset time\n",
    "        # onset_frame = np.round(onset).astype(int) - 1  # in python, the index starts from 0, so we need to subtract 1\n",
    "\n",
    "        start_idx = onset_frame - pre # <pre> volumes before the onset\n",
    "        end_idx = onset_frame + post # <post> volumes after the onset\n",
    "\n",
    "        snippet_y = np.full(pre + post + 1, np.nan) # nan fill the snippet\n",
    "        \n",
    "        valid_start = int(max(0, start_idx)) # make sure the start index is not negative\n",
    "        valid_end = int(min(len(y), end_idx + 1)) # make sure the end index is not out of bounds\n",
    "        \n",
    "        insert_start = int(valid_start - start_idx) # where to start inserting the data\n",
    "        insert_end = int(insert_start + (valid_end - valid_start)) # where to end inserting the data\n",
    "\n",
    "        snippet_y[insert_start:insert_end] = y[valid_start:valid_end] # insert the data into the snippet\n",
    "        \n",
    "        snippets_y.append(snippet_y)\n",
    "            \n",
    "    return np.array(snippets_y)\n",
    "\n",
    "for sn in participants:\n",
    "    # load participant info:\n",
    "    pinfo = pd.read_table(os.path.join(baseDir, 'participants.tsv'))\n",
    "    numTR = int(pinfo[pinfo['sn']==sn]['numTR'].values[0])\n",
    "    runs = pinfo[pinfo['sn']==sn]['glm_runs'].values[0]\n",
    "    runs = [int(run) for run in runs.split('.')]\n",
    "    \n",
    "    D = pd.read_table(os.path.join(baseDir, behavDir, f's{sn}', f's{sn}_scan.dat'))\n",
    "    T = sio.loadmat(os.path.join(baseDir, regDir, f's{sn}', f'time_series_glm{glm}.mat'), simplify_cells=True)\n",
    "    \n",
    "    f = h5py.File(os.path.join(baseDir, f'glm{glm}', f's{sn}', 'SPM.mat'), 'r')\n",
    "    SPM = f\n",
    "\n",
    "    y_adj = T['y_adj']\n",
    "    y_hat = T['y_hat']\n",
    "    y_run_avg = np.zeros(numTR)\n",
    "    y_hat_avg = np.zeros(numTR)\n",
    "    for i, run in enumerate(runs):\n",
    "        # getting the rows of the run from the SPM:\n",
    "        refs = SPM['Sess']['row'][()]\n",
    "        row = SPM[refs.flatten()[i]][()].flatten().astype(int) - 1\n",
    "        \n",
    "        t = np.arange(0, len(row), 1)\n",
    "        ons = D[D['BN']==run]['startTimeReal'].values.flatten()/1000\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(20, 4))\n",
    "        ax.vlines(ons, ymin=min(y_adj[row, region]), ymax=max(y_adj[row, region]), colors='b', lw=0.5, alpha=0.7, linestyles='--')\n",
    "        plt.plot(t, y_hat[row, region], color='r', lw=1.5)\n",
    "        plt.plot(t, y_adj[row, region], color='k', lw=1)\n",
    "        plt.xlabel('time (s)')\n",
    "        plt.ylabel('y adj')\n",
    "        plt.xlim((t[0]-2, t[-1]+2))\n",
    "        plt.title(f'run {run} - glm{glm}, region: {roi_names[region]}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'../figures/time_series/s{sn}_glm{glm}_run{run:02d}_{roi_names[region]}.pdf', bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        y_run_avg += y_adj[row, region]/len(runs)\n",
    "        y_hat_avg += y_hat[row, region]/len(runs)\n",
    "    \n",
    "    '''\n",
    "    ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "    TIME LOCKING AND AVERAGING THE TIME SERIES \n",
    "    ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "    '''\n",
    "    # load the events:\n",
    "    events = pd.read_table(os.path.join(baseDir, behavDir, f's{sn}', f'glm{glm}_events.tsv'))\n",
    "    pinfo = pd.read_table(os.path.join(baseDir, 'participants.tsv'))\n",
    "    numTR = int(pinfo[pinfo['sn']==sn]['numTR'].values[0])\n",
    "    runs = pinfo[pinfo['sn']==sn]['glm_runs'].values[0]\n",
    "    runs = [int(run) for run in runs.split('.')]\n",
    "\n",
    "    # find the onsets of the events:\n",
    "    # T = events.copy()\n",
    "    # T['y_adj'] = np.nan\n",
    "    # T['y_hat'] = np.nan\n",
    "    T = pd.DataFrame()\n",
    "    for r in range(len(roi_names)): # loop over regions\n",
    "        for i, BN in enumerate(runs):\n",
    "            tmp = pd.DataFrame()\n",
    "\n",
    "            # getting the rows of the run from SPM.mat:\n",
    "            refs = SPM['Sess']['row'][()]\n",
    "            row = SPM[refs.flatten()[i]][()].flatten().astype(int) - 1\n",
    "            \n",
    "            y_adj_reg = y_adj[row, r]\n",
    "            y_hat_reg = y_hat[row, r]\n",
    "            \n",
    "            # onsets are time relative to t=0 which alings with = 1. So, we need to subtract 1 to get the volume correpsonding to the onset.\n",
    "            onsets = np.round(events[events['BN']==BN]['onset'].values.flatten())\n",
    "\n",
    "            y_adj_cut = extract_snippets(y_adj_reg, pre_idx, post_idx, onsets)\n",
    "            y_hat_cut = extract_snippets(y_hat_reg, pre_idx, post_idx, onsets)\n",
    "            \n",
    "            tmp = pd.concat([tmp, events[events['BN']==BN]], axis=1).reset_index(drop=True)\n",
    "            tmp['region'] = r\n",
    "\n",
    "            col_names = [f\"y_adj{i}\" for i in range(y_adj_cut.shape[1])]\n",
    "            df_y_adj = pd.DataFrame(y_adj_cut, columns=col_names)\n",
    "            tmp = pd.concat([tmp, df_y_adj], axis=1).reset_index(drop=True)\n",
    "\n",
    "            col_names = [f\"y_hat{i}\" for i in range(y_hat_cut.shape[1])]\n",
    "            df_y_hat = pd.DataFrame(y_hat_cut, columns=col_names)\n",
    "            tmp = pd.concat([tmp, df_y_hat], axis=1).reset_index(drop=True)\n",
    "            \n",
    "            T = pd.concat([T, tmp], axis=0).reset_index(drop=True)\n",
    "\n",
    "    T.to_csv(os.path.join(baseDir, regDir, f's{sn}', f'bmw_time_series_cut_glm{glm}.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series time lock to stimulus onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = 5\n",
    "\n",
    "pre_idx = 8\n",
    "post_idx = 21\n",
    "\n",
    "participants = [101,102,103,104,106,107,108]\n",
    "\n",
    "conds = ['lhand','rhand','bi']\n",
    "roi_names = ['_l', 'S1_l', 'M1_l', 'PMd_l', 'PMv_l', 'SMA_l', 'V1_l', 'SPLa_l', 'SPLp_l', \n",
    "             '_r', 'S1_r', 'M1_r', 'PMd_r', 'PMv_r', 'SMA_r', 'V1_r', 'SPLa_r', 'SPLp_r']\n",
    "\n",
    "pinfo = pd.read_table(os.path.join(baseDir, 'participants.tsv'))\n",
    "TR = pinfo['TR'].values[0]/1000\n",
    "t = np.arange(-pre_idx, post_idx, TR)\n",
    "\n",
    "ymin = -0.5\n",
    "ymax = 0.5\n",
    "n_row = 8\n",
    "n_col = 2\n",
    "for cnt, sn in enumerate(participants):\n",
    "    T = pd.read_csv(os.path.join(baseDir, regDir, f's{sn}', f'bmw_time_series_cut_glm{glm}.csv'))\n",
    "    for cond in conds:\n",
    "        fig, axes = plt.subplots(n_row, n_col, figsize=(8, 16))\n",
    "        for j, r in enumerate(list(range(1, 9)) + list(range(10, 18))): # loop over regions\n",
    "            y_adj = T.loc[(T['region']==r) & (T['eventtype'].str.contains(cond, na=False)), [f'y_adj{i}' for i in range(len(t))]].mean().to_list()\n",
    "            y_adj_sem = T.loc[(T['region']==r) & (T['eventtype'].str.contains(cond, na=False)), [f'y_adj{i}' for i in range(len(t))]].sem().to_list()\n",
    "\n",
    "            y_hat = T.loc[(T['region']==r) & (T['eventtype'].str.contains(cond, na=False)), [f'y_hat{i}' for i in range(len(t))]].mean().to_list()\n",
    "\n",
    "            ax = axes[j//n_col, j%n_col]\n",
    "            ax.vlines([-7,0,7,14,21], ymin=ymin, ymax=ymax, color='b', ls='--', lw=2, alpha=0.7)\n",
    "            # ax.vlines([-2,5,12,19], ymin=min(min(y_adj),min(y_hat)), ymax=max(max(y_adj),max(y_hat)), color='k', ls='--', lw=0.4, alpha=0.85)\n",
    "            ax.plot(t, y_hat, color='r', lw=1)\n",
    "            ax.plot(t, y_adj, color='k', lw=1.1)\n",
    "            ax.fill_between(t, np.array(y_adj)-np.array(y_adj_sem), np.array(y_adj)+np.array(y_adj_sem), color='k', alpha=0.2)\n",
    "            ax.set_title(f'{roi_names[r]}')\n",
    "            ax.set_xlabel('Time')\n",
    "\n",
    "        fig.suptitle(f'{cond}, s{sn} glm{glm}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'../figures/time_series/timelock_s{sn}_glm{glm}_{cond}.pdf', bbox_inches=\"tight\")\n",
    "        if cnt == 0:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TS timelock for Gap, and Non Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = 5\n",
    "\n",
    "pre_idx = 8\n",
    "post_idx = 21\n",
    "\n",
    "participants = [101,102,103,104,106,107,108]\n",
    "\n",
    "conds = ['lhand','rhand','bi']\n",
    "roi_names = ['_l', 'S1_l', 'M1_l', 'PMd_l', 'PMv_l', 'SMA_l', 'V1_l', 'SPLa_l', 'SPLp_l', \n",
    "             '_r', 'S1_r', 'M1_r', 'PMd_r', 'PMv_r', 'SMA_r', 'V1_r', 'SPLa_r', 'SPLp_r']\n",
    "\n",
    "pinfo = pd.read_table(os.path.join(baseDir, 'participants.tsv'))\n",
    "df = pd.DataFrame()\n",
    "for cnt, sn in enumerate(participants):\n",
    "    T = pd.read_csv(os.path.join(baseDir, regDir, f's{sn}', f'bmw_time_series_cut_glm{glm}.csv'))\n",
    "    for i, r in enumerate(list(range(1, 9)) + list(range(10, 18))): # loop over regions\n",
    "        T_sorted = T.loc[T.region==r, :]\n",
    "        # Sort the DataFrame by BN first, then by TN within each BN\n",
    "        T_sorted = T_sorted.sort_values(by=['BN', 'TN']).reset_index(drop=True)\n",
    "        T_sorted['onset_diff'] = T_sorted.groupby('BN')['onset'].diff()\n",
    "        T_sorted['sn'] = sn\n",
    "        T_sorted['region_name'] = roi_names[r]\n",
    "        df = pd.concat([df, T_sorted], axis=0).reset_index(drop=True)\n",
    "\n",
    "df.to_csv(os.path.join(analysisDir, f'time_series_glm{glm}.csv'), index=False)\n",
    "\n",
    "# TR = pinfo['TR'].values[0]/1000\n",
    "# t = np.arange(-pre_idx, post_idx, TR)\n",
    "\n",
    "# ymin = -0.5\n",
    "# ymax = 0.5\n",
    "# n_row = 8\n",
    "# n_col = 2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = pd.read_csv(os.path.join(analysisDir, f'time_series_glm{glm}.csv'))\n",
    "\n",
    "pre_idx = 8\n",
    "post_idx = 21\n",
    "\n",
    "participants = [101,102,103,104,106,107,108]\n",
    "\n",
    "conds = ['lhand','rhand','bi']\n",
    "regions = ['S1_l', 'S1_r', 'M1_l', 'M1_r', 'PMd_l', 'PMd_r',\n",
    "           'PMv_l', 'PMv_r', 'SMA_l', 'SMA_r', 'V1_l', 'V1_r',\n",
    "           'SPLa_l', 'SPLa_r', 'SPLp_l', 'SPLp_r']\n",
    "\n",
    "pinfo = pd.read_table(os.path.join(baseDir, 'participants.tsv'))\n",
    "TR = pinfo['TR'].values[0]/1000\n",
    "t = np.arange(-pre_idx, post_idx, TR)\n",
    "\n",
    "gap_trials = T[T.onset_diff > 10].index - 1\n",
    "aftergap_trials = T[T.onset_diff > 10].index\n",
    "non_gap_trials = ~T.index.isin(gap_trials.union(aftergap_trials))\n",
    "\n",
    "# Select Trials:\n",
    "T_gap = T.loc[non_gap_trials].reset_index(drop=True)\n",
    "\n",
    "for cond in ['lhand', 'rhand', 'bi']:\n",
    "    df = T_gap[T_gap['eventtype'].str.contains(cond, na=False)]\n",
    "    agg_dict = {\n",
    "                **{f'y_adj{i}': 'mean' for i in range(len(t))},\n",
    "                **{f'y_hat{i}': 'mean' for i in range(len(t))}\n",
    "                }\n",
    "    df = df.groupby(['sn','region_name']).agg(agg_dict).reset_index()\n",
    "\n",
    "    ymin = -1.1\n",
    "    ymax = 1.1\n",
    "    n_row = 8\n",
    "    n_col = 2\n",
    "    fig, axes = plt.subplots(n_row, n_col, figsize=(8, 16))\n",
    "    for i,r in enumerate(regions):\n",
    "        y_adj = df.loc[(df['region_name']==r), [f'y_adj{i}' for i in range(len(t))]].mean().to_list()\n",
    "        y_adj_sem = df.loc[(df['region_name']==r), [f'y_adj{i}' for i in range(len(t))]].sem().to_list()\n",
    "        y_hat = df.loc[(df['region_name']==r), [f'y_hat{i}' for i in range(len(t))]].mean().to_list()\n",
    "        ax = axes[i//n_col, i%n_col]\n",
    "        ax.vlines([-7,0,7,14], ymin=ymin, ymax=ymax, color='b', ls='--', lw=2, alpha=0.7)\n",
    "        ax.plot(t, y_hat, color='r', lw=1)\n",
    "        ax.plot(t, y_adj, color='k', lw=1.1)\n",
    "        ax.fill_between(t, np.array(y_adj)-np.array(y_adj_sem), np.array(y_adj)+np.array(y_adj_sem), color='k', alpha=0.2)\n",
    "        ax.set_title(f'{r}')\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylim((ymin, ymax))\n",
    "    fig.suptitle(f'onset on gap trial, {cond} hand')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../figures/time_series/non_gap_trials_{cond}.pdf', bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
