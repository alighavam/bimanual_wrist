{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install matplotlib pandas seaborn\n",
    "! pip install statsmodels\n",
    "! pip install pytest\n",
    "! pip install numpy nibabel nilearn neuroimagingtools\n",
    "! pip install rsatoolbox\n",
    "! pip install PcmPy\n",
    "! pip install h5py\n",
    "! pip install mat73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import h5py\n",
    "import rsatoolbox as rsa\n",
    "from rsatoolbox.io import spm as spm_io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import surfAnalysisPy as surf\n",
    "import SUITPy as suit\n",
    "import nibabel as nb\n",
    "import nitools as nt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import PcmPy as pcm\n",
    "import glob\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "# SET PATHS:\n",
    "# baseDir = '/Users/alighavam/Desktop/Projects/bimanual_wrist/data/fMRI'\n",
    "baseDir = '/Users/alighavampour/Desktop/Projects/bimanual_wrist/data/fMRI'\n",
    "bidsDir = 'BIDS'\n",
    "anatomicalDir = 'anatomicals'\n",
    "freesurferDir = 'surfaceFreesurfer'\n",
    "surfacewbDir = 'surfaceWB' \n",
    "behavDir = 'behavioural'\n",
    "regDir = 'ROI'\n",
    "atlasDir = '/Volumes/diedrichsen_data$/data/Atlas_templates/fs_LR_32'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series per run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = 2\n",
    "region = 1\n",
    "pre_idx = 8\n",
    "post_idx = 22\n",
    "participants = [6]\n",
    "\n",
    "def extract_snippets(y, pre, post, onsets):\n",
    "        snippets_y = []\n",
    "\n",
    "        for onset in onsets:\n",
    "            start_idx = onset - pre\n",
    "            end_idx = onset + post\n",
    "\n",
    "            snippet_y = np.full(pre + post + 1, np.nan)\n",
    "            \n",
    "            valid_start = int(max(0, start_idx))\n",
    "            valid_end = int(min(len(y), end_idx + 1))\n",
    "            \n",
    "            insert_start = int(valid_start - start_idx)\n",
    "            insert_end = int(insert_start + (valid_end - valid_start))\n",
    "\n",
    "            snippet_y[insert_start:insert_end] = y[valid_start:valid_end]\n",
    "            \n",
    "            snippets_y.append(snippet_y)\n",
    "                \n",
    "        return np.array(snippets_y)\n",
    "\n",
    "for sn in participants:\n",
    "    # load participant info:\n",
    "    pinfo = pd.read_table(os.path.join(baseDir, 'participants.tsv'))\n",
    "    numTR = int(pinfo[pinfo['sn']==sn]['numTR'].values[0])\n",
    "    runs = pinfo[pinfo['sn']==sn]['glm_runs'].values[0]\n",
    "    runs = [int(run) for run in runs.split('.')]\n",
    "    \n",
    "    roi_names = ['', 'S1', 'M1', 'PMd', 'PMv', 'SMA', 'V1', 'SPLa', 'SPLp']\n",
    "    \n",
    "    D = pd.read_table(os.path.join(baseDir, behavDir, f's{sn:02d}', f'BimanualWrist_MR_{sn}.dat'))\n",
    "    T = sio.loadmat(os.path.join(baseDir, regDir, f's{sn:02d}', f'time_series_glm{glm}.mat'), simplify_cells=True)\n",
    "    \n",
    "    # SPM = mat73.loadmat(os.path.join(baseDir, f'glm{glm}', f's{sn:02d}', 'SPM.mat'))\n",
    "    f = h5py.File(os.path.join(baseDir, f'glm{glm}', f's{sn:02d}', 'SPM.mat'), 'r')\n",
    "    SPM = f['SPM']\n",
    "\n",
    "    X = SPM['xX']['X'][()].T\n",
    "    y_adj = T['y_adj']\n",
    "    y_hat = T['y_hat']\n",
    "    y_run_avg = np.zeros(numTR)\n",
    "    y_hat_avg = np.zeros(numTR)\n",
    "    for i, run in enumerate(runs):\n",
    "        # getting the rows of the run from the SPM:\n",
    "        refs = SPM['Sess']['row'][()]\n",
    "        row = SPM[refs.flatten()[i]][()].flatten().astype(int) - 1\n",
    "        \n",
    "        t = np.arange(0, len(row), 1)\n",
    "        ons = D[D['BN']==run]['startTimeReal'].values.flatten()/1000\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(20, 4))\n",
    "        ax.vlines(ons, ymin=min(y_adj[row, region]), ymax=max(y_adj[row, region]), colors='b', lw=0.5, alpha=0.7, linestyles='--')\n",
    "        plt.plot(t, y_hat[row, region], color='r', lw=1.5)\n",
    "        plt.plot(t, y_adj[row, region], color='k', lw=1)\n",
    "        plt.xlabel('time (s)')\n",
    "        plt.ylabel('y adj')\n",
    "        plt.xlim((t[0]-2, t[-1]+2))\n",
    "        plt.title(f'run {run} - glm{glm}, region: {roi_names[region]}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'./figures/bmw_time_s{sn:02d}_glm{glm}_run{run:02d}_{roi_names[region]}.pdf', bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        y_run_avg += y_adj[row, region]/len(runs)\n",
    "        y_hat_avg += y_hat[row, region]/len(runs)\n",
    "    \n",
    "    '''\n",
    "    ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "    TIME LOCKING AND AVERAGING THE TIME SERIES \n",
    "    ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
    "    '''\n",
    "    # load the events:\n",
    "    events = pd.read_table(os.path.join(baseDir, behavDir, f's{sn:02d}', f'glm{glm}_events.tsv'))\n",
    "\n",
    "    # find the onsets of the events:\n",
    "    # T = events.copy()\n",
    "    # T['y_adj'] = np.nan\n",
    "    # T['y_hat'] = np.nan\n",
    "    T = pd.DataFrame()\n",
    "    \n",
    "    blocks = runs\n",
    "    for r in range(np.shape(y_adj)[1]): # loop over regions\n",
    "        for i, BN in enumerate(blocks):\n",
    "            tmp = pd.DataFrame()\n",
    "\n",
    "            # getting the rows of the run from SPM.mat:\n",
    "            refs = SPM['Sess']['row'][()]\n",
    "            row = SPM[refs.flatten()[i]][()].flatten().astype(int) - 1\n",
    "            \n",
    "            y_adj_reg = y_adj[row, r]\n",
    "            y_hat_reg = y_hat[row, r]\n",
    "            onsets = events[events['BN']==BN]['onset']\n",
    "            y_adj_cut = extract_snippets(y_adj_reg, pre_idx, post_idx, onsets)\n",
    "            y_hat_cut = extract_snippets(y_hat_reg, pre_idx, post_idx, onsets)\n",
    "\n",
    "            tmp = pd.concat([tmp, events[events['BN']==BN]], axis=1).reset_index(drop=True)\n",
    "            tmp['region'] = r\n",
    "\n",
    "            col_names = [f\"y_adj{i}\" for i in range(y_adj_cut.shape[1])]\n",
    "            df_y_adj = pd.DataFrame(y_adj_cut, columns=col_names)\n",
    "            tmp = pd.concat([tmp, df_y_adj], axis=1).reset_index(drop=True)\n",
    "\n",
    "            col_names = [f\"y_hat{i}\" for i in range(y_hat_cut.shape[1])]\n",
    "            df_y_hat = pd.DataFrame(y_hat_cut, columns=col_names)\n",
    "            tmp = pd.concat([tmp, df_y_hat], axis=1).reset_index(drop=True)\n",
    "            \n",
    "            T = pd.concat([T, tmp], axis=0).reset_index(drop=True)\n",
    "\n",
    "    T.to_csv(os.path.join(baseDir, regDir, f's{sn:02d}', f'bmw_time_series_cut_glm{glm}.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series time lock to stimulus onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = 2\n",
    "pre_idx = 8\n",
    "post_idx = 22\n",
    "participants = [6]\n",
    "\n",
    "for sn in participants:\n",
    "    T = pd.read_csv(os.path.join(baseDir, regDir, f's{sn:02d}', f'bmw_time_series_cut_glm{glm}.csv'))\n",
    "    pinfo = pd.read_table(os.path.join(baseDir, 'participants.tsv'))\n",
    "    TR = pinfo['TR'].values[0]/1000\n",
    "\n",
    "    t = np.arange(-pre_idx, post_idx, TR)\n",
    "    roi_names = ['_l', 'S1_l', 'M1_l', 'PMd_l', 'PMv_l', 'SMA_l', 'V1_l', 'SPLa_l', 'SPLp_l', '_r', 'S1_r', 'M1_r', 'PMd_r', 'PMv_r', 'SMA_r', 'V1_r', 'SPLa_r', 'SPLp_r']\n",
    "\n",
    "    n_row = 4\n",
    "    n_col = 2\n",
    "    fig, axes = plt.subplots(n_row, n_col, figsize=(10, 10))\n",
    "    for j, r in enumerate(range(1,9)): # loop over regions\n",
    "        y_adj = T.loc[T['region']==r, [f'y_adj{i}' for i in range(len(t))]].mean().to_list()\n",
    "        y_hat = T.loc[T['region']==r, [f'y_hat{i}' for i in range(len(t))]].mean().to_list()\n",
    "\n",
    "        ax = axes[j//n_col, j%n_col]\n",
    "        ax.vlines([-7,0,7,14,21], ymin=min(min(y_adj),min(y_hat)), ymax=max(max(y_adj),max(y_hat)), color='b', ls='--', lw=2, alpha=0.7)\n",
    "        ax.vlines([-2,5,12,19], ymin=min(min(y_adj),min(y_hat)), ymax=max(max(y_adj),max(y_hat)), color='k', ls='--', lw=0.4, alpha=0.85)\n",
    "        ax.plot(t, y_hat, color='r', lw=1)\n",
    "        ax.plot(t, y_adj, color='k', lw=1.5)\n",
    "        ax.set_title(f'{roi_names[r]}')\n",
    "        ax.set_xlabel('Time')\n",
    "\n",
    "    fig.suptitle(f'Timelock to Exec, s{sn:02d} glm{glm}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./figures/bmw_timelock_s{sn:02d}_glm{glm}.pdf', bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
